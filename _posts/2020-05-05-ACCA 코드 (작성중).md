>  본 포스팅은 [Probabilistic CCA with implicit distributions](https://arxiv.org/pdf/1907.02345.pdf)에 대한 간단한 리뷰와 python 코드를 작성한 글입니다. 정확한 내용은 반드시 원문을 참조해 주시기 바랍니다.
>  1편: 논문 리뷰
>  2편: python 코드

> 추가적으로 아래의 python 코드는 **mrquincle**님의 AAE(Adversarial AutoEncoder) python 코드를 참고하여 만들었습니다.  해당 github: [https://github.com/mrquincle/keras-adversarial-autoencoders/blob/master/Keras%20Adversarial%20Autoencoder%20MNIST.ipynb](https://github.com/mrquincle/keras-adversarial-autoencoders/blob/master/Keras%20Adversarial%20Autoencoder%20MNIST.ipynb) 

## 0. setting
```python
import tensorflow as tf
import tensorflow.keras as K
from tensorflow.keras import layers
from tensorflow.keras import preprocessing
# from tensorflow.keras.models import model_from_json
print('TensorFlow version:', tf.__version__)
print('즉시 실행 모드:', tf.executing_eagerly())
print(tf.test.is_gpu_available(
      cuda_only=False,
      min_cuda_compute_capability=None
))
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())
tf.debugging.set_log_device_placement(False)
```
```

```

```python
import numpy as np
import matplotlib.pylab as plt 
import os
os.chdir('/home/jeon/Desktop/an/cca')
print('current directory:', os.getcwd())
#%%
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data() 
print(train_images.shape)
# train_images = train_images[:, :, :, np.newaxis]
img_shape = train_images.shape[1:]
x_shape = (img_shape[0], int(img_shape[1]/2))
y_shape = (img_shape[0], int(img_shape[1]/2))
xy_shape = img_shape
```

```python
latent_dim = 100
```

```python
def build_encoder():
    x = layers.Input(shape=x_shape)   
    y = layers.Input(shape=y_shape)   
    xy = layers.Input(shape=xy_shape)   
    
    hx = layers.Flatten()(x)
    hy = layers.Flatten()(y)
    hxy = layers.Flatten()(xy)
    
    hx = layers.Dense(256)(hx)
    hx = layers.LeakyReLU(alpha=0.2)(hx)
    hx = layers.Dense(256)(hx)
    hx = layers.LeakyReLU(alpha=0.2)(hx)
    
    hy = layers.Dense(256)(hy)
    hy = layers.LeakyReLU(alpha=0.2)(hy)
    hy = layers.Dense(256)(hy)
    hy = layers.LeakyReLU(alpha=0.2)(hy)
    
    hxy = layers.Dense(256)(hxy)
    hxy = layers.LeakyReLU(alpha=0.2)(hxy)
    hxy = layers.Dense(256)(hxy)
    hxy = layers.LeakyReLU(alpha=0.2)(hxy)
    
    zx = layers.Dense(latent_dim)(hx)
    zy = layers.Dense(latent_dim)(hy)
    zxy = layers.Dense(latent_dim)(hxy)
    
    return K.models.Model([x, y, xy], [zx, zy, zxy])
```

```python
def build_decoder():
    z_input = layers.Input(shape=latent_dim)
    
    zx = layers.Dense(256)(z_input)
    zx = layers.LeakyReLU(alpha=0.2)(zx)
    zx = layers.Dense(256)(zx)
    zx = layers.LeakyReLU(alpha=0.2)(zx)
    zx = layers.Dense(np.prod(x_shape), activation='tanh')(zx)
    img_x = tf.reshape(zx, [-1]+list(x_shape))
    
    zy = layers.Dense(256)(z_input)
    zy = layers.LeakyReLU(alpha=0.2)(zy)
    zy = layers.Dense(256)(zy)
    zy = layers.LeakyReLU(alpha=0.2)(zy)
    zy = layers.Dense(np.prod(y_shape), activation='tanh')(zy)
    img_y = tf.reshape(zy, [-1]+list(y_shape))
    
    img = layers.Concatenate(axis=-1)([img_x, img_y])
    
    return K.models.Model(z_input, img)
```

```python
def build_discriminator():
    z_input = layers.Input(shape=latent_dim)
    z = layers.Dense(512)(z_input)
    z = layers.LeakyReLU(alpha=0.2)(z)
    z = layers.Dense(256)(z)
    z = layers.LeakyReLU(alpha=0.2)(z)
    
    v = layers.Dense(1, activation='sigmoid')(z)
    
    return K.models.Model(z_input, v)
```

```python
discriminator = build_discriminator()
discriminator.compile('adam', 'binary_crossentropy', ['accuracy'])

encoder = build_encoder()
decoder = build_decoder()
```

```python
x_input = layers.Input(shape=x_shape)
y_input = layers.Input(shape=y_shape)
xy_input = layers.Input(shape=xy_shape)

encoded_x, encoded_y, encoded_xy = encoder([x_input, y_input, xy_input])
reconstructed_img_x = decoder(encoded_x)
reconstructed_img_y = decoder(encoded_y)
reconstructed_img_xy = decoder(encoded_xy)

'''what?'''
# For the adversarial_autoencoder model we will only train the generator
# We only set trainable to false for the discriminator when it is part of the autoencoder...
discriminator.trainable = False

validity_x = discriminator(encoded_x)
validity_y = discriminator(encoded_y)
validity_xy = discriminator(encoded_xy)

acca = K.models.Model([x_input, y_input, xy_input], 
                      [reconstructed_img_x, reconstructed_img_y, reconstructed_img_xy, validity_x, validity_y, validity_xy])
'''what?'''
# almost no weights on discriminator...
acca.compile('adam', ['mse', 'mse', 'mse', 'binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'], 
             loss_weights=[0.3333, 0.3332, 0.3332, 0.0001, 0.0001, 0.0001])
acca.summary()
discriminator.summary()
```

```python
EPOCHS = 10000
BATCH_SIZE = 256
sample_interval = 100

# scaling -1 to 1
train = (train_images.astype(np.float32) - 127.5) / 127.5
train.shape
x_train = train[:, :, :14]
x_train.shape
y_train = train[:, :, 14:]
y_train.shape

valid = np.ones((BATCH_SIZE, 1))
fake = np.zeros((BATCH_SIZE, 1))
```

```python
def sample_prior(latent_dim, batch_size):
    return np.random.normal(size=(batch_size, latent_dim))

def sample_images(latent_dim, decoder, epoch):
    r,c = 5,5

    z = sample_prior(latent_dim, r*c)
    gen_imgs = decoder.predict(z)

    gen_imgs = 0.5 * gen_imgs + 0.5 # rescaling

    fig, axs = plt.subplots(r, c)
    cnt = 0
    for i in range(r):
        for j in range(c):
            axs[i,j].imshow(gen_imgs[i*j, :, :], cmap='gray')
            axs[i,j].axis('off')
            cnt += 1
    fig.savefig("./acca_img/acca_mnist_%d.png" % epoch)
    plt.close()
```

```python
'''training'''
for epoch in range(EPOCHS):
    #=====train discriminator=====
    idx = np.random.randint(0, train.shape[0], BATCH_SIZE) # sampling random batch images -> stochasticity
    imgs_x = x_train[idx]
    imgs_y = y_train[idx]
    imgs_xy = train[idx]
    
    latent_real = np.random.normal(size=(BATCH_SIZE, latent_dim)) # TRUE sample
    latent_fake = encoder.predict([imgs_x, imgs_y, imgs_xy])
    
    d_loss_real = discriminator.train_on_batch(latent_real, valid)
    d_loss_fake = np.zeros(())
    for i in range(3):
        d_loss_fake = d_loss_fake + discriminator.train_on_batch(latent_fake[i], fake) / 3
    d_loss = np.add(d_loss_real, d_loss_fake)
    
    #=====train generator=====
    g_loss = acca.train_on_batch([imgs_x, imgs_y, imgs_xy], [imgs_xy, imgs_xy, imgs_xy] + [valid for _ in range(3)])
    
    if epoch % 500 == 0:
        # print ("%d [D loss: %f, acc: %.2f%%] [G loss: %f, mse: %f]" % (epoch, d_loss[0], 100*np.mean(d_loss[4:]), g_loss[0], g_loss[1]))
        print ("%d [D loss: %f, acc: %.2f%%] [G loss: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0]))
    
    if epoch % sample_interval == 0:
        sample_images(latent_dim, decoder, epoch)
```

```python
'''inference'''
j = 100
r = 5
given_x = test_images[j:j+r][:, :, :14]
# given_x = given_x[np.newaxis, :, :]
given_x.shape
latent_x, _, _ = encoder.predict([given_x, given_x, np.concatenate([given_x, given_x], axis=-1)])
latent_x.shape
recon_img = decoder.predict(latent_x)

img_result = [given_x, recon_img, test_images[j:j+5]]

recon_img = 0.5 * recon_img + 0.5 # rescaling
fig, axs = plt.subplots(r, 3)
cnt = 0
for i in range(r):
    axs[i,0].imshow(img_result[0][cnt, :, :], cmap='gray')
    axs[i,1].imshow(img_result[1][cnt, :, :], cmap='gray')
    axs[i,2].imshow(img_result[2][cnt, :, :], cmap='gray')
    axs[i,0].axis('off')
    axs[i,1].axis('off')
    axs[i,2].axis('off')
    cnt += 1
# fig.savefig("./acca_img/acca_mnist_%d.png" % epoch)
# plt.close()
```

## 논문
SHI, Yaxin, et al. Probabilistic CCA with Implicit Distributions. _arXiv preprint arXiv:1907.02345_, 2019.

> 코딩이나 내용에 대한 수정사항이나 더 좋은 의견은 언제든지 환영입니다! 감사합니다.
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTc1ODEzMjk5OV19
-->