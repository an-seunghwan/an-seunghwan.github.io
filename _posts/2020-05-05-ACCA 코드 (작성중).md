>  본 포스팅은 [Probabilistic CCA with implicit distributions](https://arxiv.org/pdf/1907.02345.pdf)에 대한 간단한 리뷰와 python 코드를 작성한 글입니다. 정확한 내용은 반드시 원문을 참조해 주시기 바랍니다.
>  1편: 논문 리뷰
>  2편: python 코드

## 0. setting
```python
import tensorflow as tf
import tensorflow.keras as K
from tensorflow.keras import layers
from tensorflow.keras import preprocessing
# from tensorflow.keras.models import model_from_json
print('TensorFlow version:', tf.__version__)
print('즉시 실행 모드:', tf.executing_eagerly())
print(tf.test.is_gpu_available(
      cuda_only=False,
      min_cuda_compute_capability=None
))
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())
tf.debugging.set_log_device_placement(False)
```
```

```

```python
import numpy as np
import matplotlib.pylab as plt 
import os
os.chdir('/home/jeon/Desktop/an/cca')
print('current directory:', os.getcwd())
#%%
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data() 
print(train_images.shape)
# train_images = train_images[:, :, :, np.newaxis]
img_shape = train_images.shape[1:]
x_shape = (img_shape[0], int(img_shape[1]/2))
y_shape = (img_shape[0], int(img_shape[1]/2))
xy_shape = img_shape
```

```python
latent_dim = 100
```

```python
def build_encoder():
    x = layers.Input(shape=x_shape)   
    y = layers.Input(shape=y_shape)   
    xy = layers.Input(shape=xy_shape)   
    
    hx = layers.Flatten()(x)
    hy = layers.Flatten()(y)
    hxy = layers.Flatten()(xy)
    
    hx = layers.Dense(256)(hx)
    hx = layers.LeakyReLU(alpha=0.2)(hx)
    hx = layers.Dense(256)(hx)
    hx = layers.LeakyReLU(alpha=0.2)(hx)
    
    hy = layers.Dense(256)(hy)
    hy = layers.LeakyReLU(alpha=0.2)(hy)
    hy = layers.Dense(256)(hy)
    hy = layers.LeakyReLU(alpha=0.2)(hy)
    
    hxy = layers.Dense(256)(hxy)
    hxy = layers.LeakyReLU(alpha=0.2)(hxy)
    hxy = layers.Dense(256)(hxy)
    hxy = layers.LeakyReLU(alpha=0.2)(hxy)
    
    zx = layers.Dense(latent_dim)(hx)
    zy = layers.Dense(latent_dim)(hy)
    zxy = layers.Dense(latent_dim)(hxy)
    
    return K.models.Model([x, y, xy], [zx, zy, zxy])
```

```python
def build_decoder():
    z_input = layers.Input(shape=latent_dim)
    
    zx = layers.Dense(256)(z_input)
    zx = layers.LeakyReLU(alpha=0.2)(zx)
    zx = layers.Dense(256)(zx)
    zx = layers.LeakyReLU(alpha=0.2)(zx)
    zx = layers.Dense(np.prod(x_shape), activation='tanh')(zx)
    img_x = tf.reshape(zx, [-1]+list(x_shape))
    
    zy = layers.Dense(256)(z_input)
    zy = layers.LeakyReLU(alpha=0.2)(zy)
    zy = layers.Dense(256)(zy)
    zy = layers.LeakyReLU(alpha=0.2)(zy)
    zy = layers.Dense(np.prod(y_shape), activation='tanh')(zy)
    img_y = tf.reshape(zy, [-1]+list(y_shape))
    
    img = layers.Concatenate(axis=-1)([img_x, img_y])
    
    return K.models.Model(z_input, img)
```

```python
def build_discriminator():
    z_input = layers.Input(shape=latent_dim)
    z = layers.Dense(512)(z_input)
    z = layers.LeakyReLU(alpha=0.2)(z)
    z = layers.Dense(256)(z)
    z = layers.LeakyReLU(alpha=0.2)(z)
    
    v = layers.Dense(1, activation='sigmoid')(z)
    
    return K.models.Model(z_input, v)
```

```python
discriminator = build_discriminator()
discriminator.compile('adam', 'binary_crossentropy', ['accuracy'])

encoder = build_encoder()
decoder = build_decoder()
```

```python
x_input = layers.Input(shape=x_shape)
y_input = layers.Input(shape=y_shape)
xy_input = layers.Input(shape=xy_shape)

encoded_x, encoded_y, encoded_xy = encoder([x_input, y_input, xy_input])
reconstructed_img_x = decoder(encoded_x)
reconstructed_img_y = decoder(encoded_y)
reconstructed_img_xy = decoder(encoded_xy)

'''what?'''
# For the adversarial_autoencoder model we will only train the generator
# We only set trainable to false for the discriminator when it is part of the autoencoder...
discriminator.trainable = False

validity_x = discriminator(encoded_x)
validity_y = discriminator(encoded_y)
validity_xy = discriminator(encoded_xy)

acca = K.models.Model([x_input, y_input, xy_input], 
                      [reconstructed_img_x, reconstructed_img_y, reconstructed_img_xy, validity_x, validity_y, validity_xy])
'''what?'''
# almost no weights on discriminator...
acca.compile('adam', ['mse', 'mse', 'mse', 'binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'], 
             loss_weights=[0.3333, 0.3332, 0.3332, 0.0001, 0.0001, 0.0001])
acca.summary()
discriminator.summary()
```

```python
EPOCHS = 10000
BATCH_SIZE = 256
sample_interval = 100

# scaling -1 to 1
train = (train_images.astype(np.float32) - 127.5) / 127.5
train.shape
x_train = train[:, :, :14]
x_train.shape
y_train = train[:, :, 14:]
y_train.shape

valid = np.ones((BATCH_SIZE, 1))
fake = np.zeros((BATCH_SIZE, 1))
```

## 논문
SHI, Yaxin, et al. Probabilistic CCA with Implicit Distributions. _arXiv preprint arXiv:1907.02345_, 2019.

> 코딩이나 내용에 대한 수정사항이나 더 좋은 의견은 언제든지 환영입니다! 감사합니다.
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTk4MjE5NjY3Ml19
-->