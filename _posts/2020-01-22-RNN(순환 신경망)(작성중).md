---
title: "Keras로 이해하는 RNN(순환 신경망)(작성중)"
excerpt: "Recurrent Neural Network"
toc: true
toc_sticky: true

author_profile: false
use_math: true

date: 2020-01-22 17:00:00 -0000
categories: 
  - NLP
tags:
  - tensorflow 2.0
  - keras
---
## What is RNN?

RNN, 순환 신경망은 기존의 잘 알려진 DNN과 유사하지만, 은닉층(hidden layer)의 결과 벡터가 다시 은닉층에 입력된다는 점이 가장 다르다. 이러한 점 때문에 재귀적(recurrent)이라는 이름이 붙게 되었다. 또한 기존에 은닉층과 같이 사용되는 노드(node)라는 용어 대신 **cell**이라는 용어를 더 많이 사용한다. 즉, RNN hidden layer의 cell이 DNN hidden layer의 node에 대응된다고 생각하면 좋다.

용어를 다음과 같이 정리하자.

$$
t: \me
$$
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwMDk3NDk5NjAsMjExNjIwNDc1MF19
-->