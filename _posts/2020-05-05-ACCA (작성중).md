>  본 포스팅은 [Probabilistic CCA with implicit distributions](https://arxiv.org/pdf/1907.02345.pdf)에 대한 간단한 리뷰와 python 코드를 작성한 글입니다. 정확한 내용은 반드시 원문을 참조해 주시기 바랍니다.

## 0. 용어의 번역

- source : 원문 (NMT 모형의 번역 대상)
- attend : 고려되다.

## 2. Neural Machine Translation(NMT)

NMT system은 원문 문장($$)

논문에서는 다음과 같은 두 가지 attention-based 모형을 제안한다: *global* approach에서는 모든 원문의 단어들이 고려된다. 그리고 *local* approach에서는 원문의 단어 중 일부만이 고려된다.

## 논문
LUONG, Minh-Thang; PHAM, Hieu; MANNING, Christopher D. Effective approaches to attention-based neural machine translation. _arXiv preprint arXiv:1508.04025_, 2015.

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE0NDI3OTE5MzVdfQ==
-->