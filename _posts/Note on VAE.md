---
title: "Subword Regularization(논문 읽기)"
excerpt: "Improving Neural Network Translation Models with Multiple Subword Candidates"
toc: true
toc_sticky: true

author_profile: false
use_math: true

date: 2020-01-08 20:00:00 -0000
categories: 
  - NLP
tags:
  - 논문 읽기
  - OOV
  - tokenizer
  - 전처리
---
> Variational Inference, VAE 관련 여러 논문들과 블로그들을 보고 중요하다고 생각되는 수식이 아닌 아이디어 위주의 정리 포스팅입니다.
> 개인적인 정리 목적의 글임을 밝힙니다.

## 0. 참고 논문 및 블로그


## 1.  VAE

### . purpose
1 . sampling maximize data log-likelihood

### . latent variable model
latent space learning

### . ELBO

### . variational approximation
ancestral sampling

### . tug-of-war objective

### . practical coding issues with continuous output data


## . Posterior Collapse

### . Probabilistic PCA
1. distributions
2. posterior collapse
3. stability of stationary points

### . Linear VAE vs pPCA
1. model 
2. objective
3. Deep VAE


> 수정사항이나 질문은 댓글에 남겨주시면 감사하겠습니다 :)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEwMzQ5NjYxMDYsMTU0NDg5ODg4MF19
-->